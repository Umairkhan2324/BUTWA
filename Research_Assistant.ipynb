{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOz1Y3G7isSK2Pl9DfEN5jJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Umairkhan2324/BUTWA/blob/main/Research_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEKKwfwi1AEj",
        "outputId": "9ded30f7-13a5-4f7a-97e1-32c8affd269e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-core<0.4,>=0.3 (from langchain-groq)\n",
            "  Downloading langchain_core-0.3.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq<1,>=0.4.1->langchain-groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-groq) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4,>=0.3->langchain-groq)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4,>=0.3->langchain-groq)\n",
            "  Downloading langsmith-0.1.130-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-groq) (24.1)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.4,>=0.3->langchain-groq)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain-groq)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-groq)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-groq) (2.32.3)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-groq)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-groq) (2.2.3)\n",
            "Downloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.8-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.130-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, h11, requests-toolbelt, jsonpatch, httpcore, httpx, langsmith, groq, langchain-core, langchain-groq\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed groq-0.11.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.8 langchain-groq-0.2.0 langsmith-0.1.130 orjson-3.10.7 requests-toolbelt-1.0.0 tenacity-8.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIjlqcRL1IVH",
        "outputId": "dbe5c767-e108-4ddf-f9b4-ece37a8ec65f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GROQ_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_community langchain_core tavily-python wikipedia\n"
      ],
      "metadata": {
        "id": "j9U2otLU1tlO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "%env LANGCHAIN_API_KEY = {userdata.get('LANGCHAIN_API_KEY')}\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvA8QcMG141r",
        "outputId": "aab70221-a61e-456e-a33a-0afb315c73bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: LANGCHAIN_API_KEY=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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama3-70B-8192\",\n",
        "    temperature=0.1,\n",
        ")"
      ],
      "metadata": {
        "id": "Rs11ufH12Soz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Write about role of agentic AI in future of education under 80 words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S92Mlc9p23ky",
        "outputId": "ec4b703d-3f9b-407e-fdb9-8d1e74dc76de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='In the future of education, agentic AI will play a transformative role by personalizing learning experiences, automating grading, and providing real-time feedback. AI agents will act as virtual teaching assistants, freeing human instructors to focus on high-touch, high-value tasks. They will also help identify learning gaps, recommend customized learning paths, and facilitate collaborative learning environments, ultimately leading to more effective and efficient education.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 25, 'total_tokens': 106, 'completion_time': 0.255904845, 'prompt_time': 0.000814972, 'queue_time': 0.012307466999999999, 'total_time': 0.256719817}, 'model_name': 'llama3-70B-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None}, id='run-580a2f22-38c1-4998-b479-628d5a79da66-0', usage_metadata={'input_tokens': 25, 'output_tokens': 81, 'total_tokens': 106})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Analyst(BaseModel):\n",
        "    affiliation: str = Field(\n",
        "        description=\"Primary affiliation of the analyst.\",\n",
        "    )\n",
        "    name: str = Field(\n",
        "        description=\"Name of the analyst.\"\n",
        "    )\n",
        "    role: str = Field(\n",
        "        description=\"Role of the analyst in the context of the topic.\",\n",
        "    )\n",
        "    description: str = Field(\n",
        "        description=\"Description of the analyst focus, concerns, and motives.\",\n",
        "    )\n",
        "    @property\n",
        "    def persona(self) -> str:\n",
        "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
        "\n",
        "class Perspectives(BaseModel):\n",
        "    analysts: List[Analyst] = Field(\n",
        "        description=\"Comprehensive list of analysts with their roles and affiliations.\",\n",
        "    )\n",
        "\n",
        "\n",
        "class GenerateAnalystsState(TypedDict):\n",
        "    topic: str # Research topic\n",
        "    max_analysts: int # Number of analysts\n",
        "    human_analyst_feedback: str # Human feedback\n",
        "    analysts: List[Analyst] # Analyst asking questions"
      ],
      "metadata": {
        "id": "R1ms-7Vk3E9x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ayaz = Analyst(affiliation=\"Engineering Team\", name=\"Ayaz\", role=\"Engineer\", description=\"responsible for giving best engineering solutions\")\n",
        "# print(ayaz)\n",
        "# print(type(ayaz))\n",
        "print(\"---\" * 20)\n",
        "print(Ayaz.persona)\n",
        "# print(type(ayaz.persona))\n",
        "print(\"---\" * 20)\n",
        "\n",
        "Amna = Analyst(name=\"Amna\", role=\"Biologist\", affiliation=\"Biology Team\", description=\"Making things look pretty\")\n",
        "print(\"---\" * 20)\n",
        "print(Amna.persona)\n",
        "# print(type(amna.persona))\n",
        "print(\"---\" * 20)\n",
        "# Ayaz and Amna are analysts\n",
        "\n",
        "# Perspectives is like a box that holds both Bob and Sarah\n",
        "perspectives = Perspectives(analysts=[Ayaz, Amna])\n",
        "print(perspectives)\n",
        "# You now have a list of all the analysts in one place\n",
        "\n",
        "# Now we create a plan with some information\n",
        "generate_state = GenerateAnalystsState(\n",
        "    topic=\"Eco-friendly industrial practices\",\n",
        "    max_analysts=3,\n",
        "    human_analyst_feedback=\"Make sure to choose Best and feasible practices for inustries to protect the environment!\",\n",
        "    analysts=[Ayaz, Amna]\n",
        ")\n",
        "print(\"---\" * 20)\n",
        "print(generate_state)\n",
        "print(\"---\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sen5tKVO3Okk",
        "outputId": "85293abd-a3b5-4eb9-cc6a-140ad4348f8a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "Name: Ayaz\n",
            "Role: Engineer\n",
            "Affiliation: Engineering Team\n",
            "Description: responsible for giving best engineering solutions\n",
            "\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "Name: Amna\n",
            "Role: Biologist\n",
            "Affiliation: Biology Team\n",
            "Description: Making things look pretty\n",
            "\n",
            "------------------------------------------------------------\n",
            "analysts=[Analyst(affiliation='Engineering Team', name='Ayaz', role='Engineer', description='responsible for giving best engineering solutions'), Analyst(affiliation='Biology Team', name='Amna', role='Biologist', description='Making things look pretty')]\n",
            "------------------------------------------------------------\n",
            "{'topic': 'Eco-friendly industrial practices', 'max_analysts': 3, 'human_analyst_feedback': 'Make sure to choose Best and feasible practices for inustries to protect the environment!', 'analysts': [Analyst(affiliation='Engineering Team', name='Ayaz', role='Engineer', description='responsible for giving best engineering solutions'), Analyst(affiliation='Biology Team', name='Amna', role='Biologist', description='Making things look pretty')]}\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}